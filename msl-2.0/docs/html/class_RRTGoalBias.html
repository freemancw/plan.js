<HEAD>
<TITLE>Motion Strategy Library</TITLE>
</HEAD>

<body bgcolor="#ffffff">

<center><img src="msl.jpg"></center>

<p>


<!-- Generated by Doxygen 1.2.6 -->
<center>
<a class="qindex" href="index.html">Main Page</a> &nbsp; <a class="qindex" href="hierarchy.html">Class Hierarchy</a> &nbsp; <a class="qindex" href="annotated.html">Compound List</a> &nbsp; <a class="qindex" href="files.html">File List</a> &nbsp; <a class="qindex" href="functions.html">Compound Members</a> &nbsp; <a class="qindex" href="globals.html">File Members</a> &nbsp; </center>
<hr><h1>RRTGoalBias  Class Reference</h1>With some probability, choose the goal instead of a random sample. 
<a href="#_details">More...</a>
<p>
<code>#include &lt;<a class="el" href="rrt_h-source.html">rrt.h</a>&gt;</code>
<p>
<p>Inheritance diagram for RRTGoalBias::
<p><center><img src="class_RRTGoalBias.gif" usemap="#RRTGoalBias_map" border="0"></center>
<map name="RRTGoalBias_map">
<area href="class_RRT.html" alt="RRT" shape="rect" coords="0,168,121,192">
<area href="class_IncrementalPlanner.html" alt="IncrementalPlanner" shape="rect" coords="0,112,121,136">
<area href="class_Planner.html" alt="Planner" shape="rect" coords="0,56,121,80">
<area href="class_Solver.html" alt="Solver" shape="rect" coords="0,0,121,24">
<area href="class_RRTCon.html" alt="RRTCon" shape="rect" coords="0,280,121,304">
<area href="class_RRTSlide.html" alt="RRTSlide" shape="rect" coords="0,336,121,360">
</map>
<a href="class_RRTGoalBias-members.html">List of all members.</a><table border=0 cellpadding=0 cellspacing=0>
<tr><td colspan=2><br><h2>Public Methods</h2></td></tr>
<tr><td nowrap align=right valign=top>&nbsp;</td><td valign=bottom><a class="el" href="class_RRTGoalBias.html#a0">RRTGoalBias</a> (<a class="el" href="class_Problem.html">Problem</a> *p)</td></tr>
<tr><td nowrap align=right valign=top>virtual&nbsp;</td><td valign=bottom><a class="el" href="class_RRTGoalBias.html#a1">~RRTGoalBias</a> ()</td></tr>
<tr><td colspan=2><br><h2>Public Attributes</h2></td></tr>
<tr><td nowrap align=right valign=top>double&nbsp;</td><td valign=bottom><a class="el" href="class_RRTGoalBias.html#m0">GoalProb</a></td></tr>
<tr><td colspan=2><br><h2>Protected Methods</h2></td></tr>
<tr><td nowrap align=right valign=top>virtual <a class="el" href="class_MSLVector.html">MSLVector</a>&nbsp;</td><td valign=bottom><a class="el" href="class_RRTGoalBias.html#b0">ChooseState</a> ()</td></tr>
<tr><td>&nbsp;</td><td><font size=-1><em>Pick a state using some sampling technique.</em></font><br><br></td></tr>
</table>
<hr><a name="_details"></a><h2>Detailed Description</h2>
With some probability, choose the goal instead of a random sample.
<p>
Instead of choosing a state at random, this planner chooses with probability GoalProb the GoalState. It can be considered as a  biased coin toss in which heads yields the goal state, and tails yields a random sample. 
<p>
<hr><h2>Constructor &amp; Destructor Documentation</h2>
<a name="a0" doxytag="RRTGoalBias::RRTGoalBias"></a><p>
<table width="100%" cellpadding="2" cellspacing="0" border="0">
  <tr>
    <td class="md">
      <table cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td nowrap valign="top"><b> 
RRTGoalBias::RRTGoalBias (
          </b></td>
          <td valign="bottom"><b>
<a class="el" href="class_Problem.html">Problem</a> * <em>p</em>&nbsp;)
          </b></td>
        </tr>

      </table>
    </td>
  </tr>
</table>
<table cellspacing=5 cellpadding=0 border=0>
  <tr>
    <td>
      &nbsp;
    </td>
    <td>

<p>
    </td>
  </tr>
</table>
<a name="a1" doxytag="RRTGoalBias::~RRTGoalBias"></a><p>
<table width="100%" cellpadding="2" cellspacing="0" border="0">
  <tr>
    <td class="md">
      <table cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td nowrap valign="top"><b> 
RRTGoalBias::~RRTGoalBias (
          </b></td>
          <td valign="bottom"><b>
)<code> [inline, virtual]</code>
          </b></td>
        </tr>

      </table>
    </td>
  </tr>
</table>
<table cellspacing=5 cellpadding=0 border=0>
  <tr>
    <td>
      &nbsp;
    </td>
    <td>

<p>
    </td>
  </tr>
</table>
<hr><h2>Member Function Documentation</h2>
<a name="b0" doxytag="RRTGoalBias::ChooseState"></a><p>
<table width="100%" cellpadding="2" cellspacing="0" border="0">
  <tr>
    <td class="md">
      <table cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td nowrap valign="top"><b> 
virtual <a class="el" href="class_MSLVector.html">MSLVector</a> RRTGoalBias::ChooseState (
          </b></td>
          <td valign="bottom"><b>
)<code> [protected, virtual]</code>
          </b></td>
        </tr>

      </table>
    </td>
  </tr>
</table>
<table cellspacing=5 cellpadding=0 border=0>
  <tr>
    <td>
      &nbsp;
    </td>
    <td>

<p>
Pick a state using some sampling technique.
<p>

<p>
Reimplemented from <a class="el" href="class_RRT.html#b4">RRT</a>.    </td>
  </tr>
</table>
<hr><h2>Member Data Documentation</h2>
<a name="m0" doxytag="RRTGoalBias::GoalProb"></a><p>
<table width="100%" cellpadding="2" cellspacing="0" border="0">
  <tr>
    <td class="md">
      <table cellpadding="0" cellspacing="0" border="0">
        <tr>
          <td nowrap valign="top"><b> 
double RRTGoalBias::GoalProb
          </b></td>
        </tr>

      </table>
    </td>
  </tr>
</table>
<table cellspacing=5 cellpadding=0 border=0>
  <tr>
    <td>
      &nbsp;
    </td>
    <td>

<p>
    </td>
  </tr>
</table>
<hr>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="rrt_h-source.html">rrt.h</a></ul>
<HEAD>
<TITLE>Motion Strategy Library</TITLE>
</HEAD>

<p>

<hr>

Web page maintained by 
<a href="http://janowiec.cs.iastate.edu/~lavalle">Steve LaValle</a><br>

Partial support provided by NSF CAREER Award IRI-970228 (LaValle),
Honda Research.<br>

Contributors:  Anna Atramentov, Peng Cheng, James Kuffner, Steve LaValle, and Libo Yang.<br>
